{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMlAocMvW0bvl+4GFmeAnY8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyasha2011/quantum/blob/main/optimizedquantumVQC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1: Install Dependencies (after restart)\n",
        "!pip install pennylane torch torchvision pillow captcha numpy matplotlib -q\n",
        "print(\"✅ Installation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvREEVuNTL9S",
        "outputId": "37823a2a-96aa-4636-f45b-add0c114352a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m934.3/934.3 kB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m144.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Installation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from captcha.image import ImageCaptcha\n",
        "from tqdm import tqdm\n",
        "\n",
        "CHAR_SET = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
        "MIN_LENGTH, MAX_LENGTH = 4, 6\n",
        "IMG_WIDTH, IMG_HEIGHT = 180, 60\n",
        "TRAIN_SIZE, VAL_SIZE, TEST_SIZE = 2000, 500, 500\n",
        "\n",
        "BASE_DIR = \"/content/captcha_dataset\"\n",
        "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
        "VAL_DIR = os.path.join(BASE_DIR, \"val\")\n",
        "TEST_DIR = os.path.join(BASE_DIR, \"test\")\n",
        "\n",
        "for path in [TRAIN_DIR, VAL_DIR, TEST_DIR]:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def random_captcha_text(min_len=MIN_LENGTH, max_len=MAX_LENGTH):\n",
        "    length = random.randint(min_len, max_len)\n",
        "    return ''.join(random.choices(CHAR_SET, k=length))\n",
        "\n",
        "def generate_dataset(split_dir, num_samples):\n",
        "    image_captcha = ImageCaptcha(width=IMG_WIDTH, height=IMG_HEIGHT)\n",
        "    for _ in tqdm(range(num_samples), desc=f\"Generating {split_dir.split('/')[-1]}\"):\n",
        "        text = random_captcha_text()\n",
        "        image = image_captcha.generate_image(text).convert(\"RGB\")\n",
        "        file_path = os.path.join(split_dir, f\"{text}.png\")\n",
        "        image.save(file_path)\n",
        "\n",
        "generate_dataset(TRAIN_DIR, TRAIN_SIZE)\n",
        "generate_dataset(VAL_DIR, VAL_SIZE)\n",
        "generate_dataset(TEST_DIR, TEST_SIZE)\n",
        "\n",
        "print(\"✅ Dataset generation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcIkFpGTTf1",
        "outputId": "7fcf2843-3465-4453-a7f1-6bdc17313c91"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating train: 100%|██████████| 2000/2000 [00:18<00:00, 109.03it/s]\n",
            "Generating val: 100%|██████████| 500/500 [00:02<00:00, 174.68it/s]\n",
            "Generating test: 100%|██████████| 500/500 [00:02<00:00, 171.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset generation complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "BASE_DIR = \"/content/captcha_dataset\"\n",
        "SPLITS = [\"train\", \"val\", \"test\"]\n",
        "OUT_SUBDIR = \"chars_8x8\"\n",
        "\n",
        "for split in SPLITS:\n",
        "    split_dir = os.path.join(BASE_DIR, split)\n",
        "    out_dir = os.path.join(split_dir, OUT_SUBDIR)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    for fname in tqdm(sorted(os.listdir(split_dir)), desc=f\"Segment {split}\"):\n",
        "        if not fname.lower().endswith(\".png\"):\n",
        "            continue\n",
        "\n",
        "        text = fname[:-4]  # drop .png\n",
        "        img = Image.open(os.path.join(split_dir, fname)).convert(\"L\")\n",
        "        W, H = img.size\n",
        "        n = len(text)\n",
        "        slice_w = W / n\n",
        "\n",
        "        for i, ch in enumerate(text):\n",
        "            left = int(round(i * slice_w))\n",
        "            right = int(round((i + 1) * slice_w))\n",
        "            crop = img.crop((left, 0, right, H))\n",
        "            crop = crop.resize((8, 8), Image.BILINEAR)\n",
        "            save_name = f\"{text}_{i}_{ch}.png\"\n",
        "            crop.save(os.path.join(out_dir, save_name))\n",
        "\n",
        "print(\"✅ Character segmentation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQROZve4TU5l",
        "outputId": "8abe361c-6fff-4561-87c2-4107030a5886"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Segment train: 100%|██████████| 2001/2001 [00:03<00:00, 595.39it/s]\n",
            "Segment val: 100%|██████████| 501/501 [00:01<00:00, 302.70it/s]\n",
            "Segment test: 100%|██████████| 501/501 [00:02<00:00, 239.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Character segmentation complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset_chars_fixed.py\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "CHAR_SET = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
        "\n",
        "class CaptchaCharDataset(Dataset):\n",
        "    \"\"\"Load pre-segmented 8x8 character images from chars_8x8 subdirectory\"\"\"\n",
        "    def __init__(self, root_dir, img_size=8):\n",
        "        self.samples = []\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Look in the chars_8x8 subdirectory for segmented characters\n",
        "        chars_dir = os.path.join(root_dir, \"chars_8x8\")\n",
        "        if not os.path.exists(chars_dir):\n",
        "            raise ValueError(f\"Segmented chars directory not found: {chars_dir}\")\n",
        "\n",
        "        for fname in os.listdir(chars_dir):\n",
        "            if fname.endswith('.png'):\n",
        "                # Filename format: CAPTCHA_TEXT_position_character.png\n",
        "                # Example: ABC123_0_A.png\n",
        "                parts = fname[:-4].split('_')\n",
        "                if len(parts) >= 3:\n",
        "                    char_label = parts[-1]  # Last part is the character\n",
        "                    if char_label in CHAR_SET:\n",
        "                        self.samples.append((os.path.join(chars_dir, fname), char_label))\n",
        "\n",
        "        self.char_to_idx = {ch: i for i, ch in enumerate(CHAR_SET)}\n",
        "        print(f\"Loaded {len(self.samples)} character samples from {chars_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label_char = self.samples[idx]\n",
        "\n",
        "        # Load the already-segmented 8x8 character image\n",
        "        img = Image.open(img_path).convert('L')\n",
        "        img = img.resize((self.img_size, self.img_size), Image.BILINEAR)\n",
        "\n",
        "        # Normalize to [0, 1]\n",
        "        x = np.array(img).flatten() / 255.0\n",
        "        y = self.char_to_idx[label_char]\n",
        "\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIFGuCqTTWx1",
        "outputId": "408f628b-bddf-4159-fd98-1087fa128621"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset_chars_fixed.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== CELL 5 (FIXED) =====\n",
        "# Define Advanced Quantum Model with better error handling\n",
        "%%writefile quantum_vqc_advanced.py\n",
        "\n",
        "import pennylane as qml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "CHAR_SET = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
        "\n",
        "class FullyQuantumVQC(nn.Module):\n",
        "    \"\"\"\n",
        "    Advanced Fully Quantum VQC with Data Re-uploading\n",
        "    - 6 qubits, 3 layers\n",
        "    - Multiple measurements (Z, ZZ, ZZZ)\n",
        "    \"\"\"\n",
        "    def __init__(self, n_qubits=6, n_layers=3, n_classes=len(CHAR_SET)):\n",
        "        super().__init__()\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_layers = n_layers\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "        @qml.qnode(self.dev, interface=\"torch\", diff_method=\"backprop\")\n",
        "        def quantum_circuit(inputs, weights):\n",
        "            # Ensure inputs are float32\n",
        "            inputs = inputs.float()\n",
        "\n",
        "            # Data re-uploading architecture\n",
        "            for layer in range(n_layers):\n",
        "                # Re-encode data at each layer\n",
        "                qml.AmplitudeEmbedding(inputs, wires=range(n_qubits),\n",
        "                                      pad_with=0.0, normalize=True)\n",
        "\n",
        "                # Variational rotations\n",
        "                for i in range(n_qubits):\n",
        "                    qml.RY(weights[layer, i, 0], wires=i)\n",
        "                    qml.RZ(weights[layer, i, 1], wires=i)\n",
        "\n",
        "                # Entanglement\n",
        "                for i in range(n_qubits - 1):\n",
        "                    qml.CNOT(wires=[i, i + 1])\n",
        "                qml.CNOT(wires=[n_qubits - 1, 0])\n",
        "\n",
        "            # Multiple measurements\n",
        "            measurements = []\n",
        "\n",
        "            # Single-qubit Z measurements\n",
        "            for i in range(n_qubits):\n",
        "                measurements.append(qml.expval(qml.PauliZ(i)))\n",
        "\n",
        "            # Two-qubit ZZ correlations\n",
        "            for i in range(n_qubits - 1):\n",
        "                measurements.append(qml.expval(qml.PauliZ(i) @ qml.PauliZ(i + 1)))\n",
        "\n",
        "            # Three-qubit ZZZ correlations\n",
        "            for i in range(n_qubits - 2):\n",
        "                measurements.append(qml.expval(qml.PauliZ(i) @ qml.PauliZ(i + 1) @ qml.PauliZ(i + 2)))\n",
        "\n",
        "            return measurements\n",
        "\n",
        "        self.circuit = quantum_circuit\n",
        "        self.q_weights = nn.Parameter(torch.randn(n_layers, n_qubits, 2, dtype=torch.float32) * 0.1)\n",
        "\n",
        "        # Total measurements: 6 + 5 + 4 = 15\n",
        "        n_measurements = n_qubits + (n_qubits - 1) + (n_qubits - 2)\n",
        "\n",
        "        # Minimal classical output layer\n",
        "        self.output_layer = nn.Linear(n_measurements, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        quantum_features = []\n",
        "\n",
        "        # Ensure input is float32\n",
        "        x = x.float()\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            try:\n",
        "                measurements = self.circuit(x[i], self.q_weights)\n",
        "\n",
        "                # Convert to tensor with explicit dtype\n",
        "                if isinstance(measurements, (list, tuple)):\n",
        "                    meas_list = []\n",
        "                    for m in measurements:\n",
        "                        if torch.is_tensor(m):\n",
        "                            meas_list.append(m.detach().float())\n",
        "                        else:\n",
        "                            meas_list.append(torch.tensor(float(m), dtype=torch.float32))\n",
        "                    measurements_tensor = torch.stack(meas_list).to(x.device)\n",
        "                else:\n",
        "                    measurements_tensor = measurements.detach().float()\n",
        "\n",
        "                quantum_features.append(measurements_tensor)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in quantum circuit for sample {i}: {e}\")\n",
        "                # Return zeros as fallback\n",
        "                n_measurements = self.n_qubits + (self.n_qubits - 1) + (self.n_qubits - 2)\n",
        "                quantum_features.append(torch.zeros(n_measurements, dtype=torch.float32, device=x.device))\n",
        "\n",
        "        quantum_features = torch.stack(quantum_features)\n",
        "        logits = self.output_layer(quantum_features)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csv7MmOdTYQV",
        "outputId": "8db572cb-d1b7-4e8e-b559-6645fd71ea11"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing quantum_vqc_advanced.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== CELL 6 (RE-RUN) =====\n",
        "# Reimport the fixed model\n",
        "import sys\n",
        "if 'quantum_vqc_advanced' in sys.modules:\n",
        "    del sys.modules['quantum_vqc_advanced']\n",
        "\n",
        "from quantum_vqc_advanced import FullyQuantumVQC\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"✅ Advanced model imported successfully!\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Test it thoroughly\n",
        "test_model = FullyQuantumVQC(n_qubits=6, n_layers=3).to(device)\n",
        "test_input = torch.randn(4, 64).to(device)\n",
        "test_output = test_model(test_input)\n",
        "print(f\"Test passed! Output shape: {test_output.shape}\")\n",
        "print(f\"Output dtype: {test_output.dtype}\")\n",
        "print(f\"Output contains NaN: {torch.isnan(test_output).any()}\")\n",
        "print(f\"Output contains Inf: {torch.isinf(test_output).any()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts4fLUS9TZ4W",
        "outputId": "098b2c55-d5d2-42f0-eee4-b9f9a95df1e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pennylane/__init__.py:209: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.7.2 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Advanced model imported successfully!\n",
            "Using device: cuda\n",
            "Test passed! Output shape: torch.Size([4, 36])\n",
            "Output dtype: torch.float32\n",
            "Output contains NaN: False\n",
            "Output contains Inf: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== CELL 7 =====\n",
        "# Prepare data loaders\n",
        "from torch.utils.data import DataLoader\n",
        "from dataset_chars_fixed import CaptchaCharDataset\n",
        "\n",
        "train_dataset = CaptchaCharDataset(\"/content/captcha_dataset/train\")\n",
        "val_dataset = CaptchaCharDataset(\"/content/captcha_dataset/val\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, num_workers=2)\n",
        "\n",
        "print(f\"Training batches: {len(train_loader)}\")\n",
        "print(f\"Validation batches: {len(val_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dgT6dLPTbZZ",
        "outputId": "a1953f82-ce01-42d8-e202-f538cc82e9c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 9920 character samples from /content/captcha_dataset/train/chars_8x8\n",
            "Loaded 2487 character samples from /content/captcha_dataset/val/chars_8x8\n",
            "Training batches: 620\n",
            "Validation batches: 156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== CELL 8 (UPDATED WITH BETTER LOGGING) =====\n",
        "# Training function with detailed epoch logging\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_quantum_model(model, train_loader, val_loader, device, epochs=50, lr=0.005, model_name=\"Advanced Quantum VQC\"):\n",
        "    model = model.to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-5)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_acc': [], 'lr': []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss, train_correct, train_total = 0, 0, 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"[{model_name}] Epoch {epoch+1}/{epochs}\")\n",
        "        for batch_idx, (x, y) in enumerate(pbar):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "\n",
        "            # Check for None or invalid output\n",
        "            if logits is None:\n",
        "                print(f\"WARNING: Model returned None at batch {batch_idx}\")\n",
        "                continue\n",
        "\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "\n",
        "            # Check for NaN loss\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"WARNING: NaN loss at batch {batch_idx}, skipping\")\n",
        "                continue\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            preds = logits.argmax(dim=1)\n",
        "            train_correct += (preds == y).sum().item()\n",
        "            train_total += y.size(0)\n",
        "\n",
        "            # Update progress bar with current metrics\n",
        "            current_acc = 100 * train_correct / train_total if train_total > 0 else 0\n",
        "            current_lr = scheduler.get_last_lr()[0]\n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'acc': f'{current_acc:.2f}%',\n",
        "                'lr': f'{current_lr:.6f}'\n",
        "            })\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct, val_total = 0, 0\n",
        "        val_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                logits = model(x)\n",
        "\n",
        "                if logits is not None:\n",
        "                    loss = F.cross_entropy(logits, y)\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "                    preds = logits.argmax(dim=1)\n",
        "                    val_correct += (preds == y).sum().item()\n",
        "                    val_total += y.size(0)\n",
        "\n",
        "        train_acc = 100 * train_correct / train_total if train_total > 0 else 0\n",
        "        val_acc = 100 * val_correct / val_total if val_total > 0 else 0\n",
        "        avg_train_loss = train_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
        "        avg_val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
        "        current_lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['lr'].append(current_lr)\n",
        "\n",
        "        # Print detailed epoch summary (matching your desired format)\n",
        "        print(f\"\\n[{model_name}] Epoch {epoch+1}/{epochs}:\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"  Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
        "        print(f\"  LR: {current_lr:.6f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'val_acc': val_acc,\n",
        "                'history': history\n",
        "            }, 'best_advanced_quantum.pt')\n",
        "            print(f\"  ✅ New best model saved! Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        scheduler.step()\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "    return history\n",
        "\n",
        "print(\"✅ Training function with detailed logging ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNZCJ9f1TdUB",
        "outputId": "9ff6ab76-3a31-48ac-85b4-017fe03b0fb1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training function with detailed logging ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== CELL 9 (RE-RUN TRAINING) =====\n",
        "# TRAIN THE ADVANCED MODEL\n",
        "from quantum_vqc_advanced import FullyQuantumVQC\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TRAINING ADVANCED QUANTUM VQC MODEL\")\n",
        "print(\"  - 6 qubits with 64-amplitude encoding\")\n",
        "print(\"  - 3 layers with data re-uploading\")\n",
        "print(\"  - 15 quantum measurements (Z, ZZ, ZZZ)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "model = FullyQuantumVQC(n_qubits=6, n_layers=3)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "quantum_params = model.q_weights.numel()\n",
        "print(f\"\\nTotal parameters: {total_params}\")\n",
        "print(f\"Quantum parameters: {quantum_params}\")\n",
        "print(f\"Classical parameters: {total_params - quantum_params}\\n\")\n",
        "\n",
        "history = train_quantum_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    epochs=20,  # Change to 10 for quick test\n",
        "    lr=0.005,\n",
        "    model_name=\"Advanced Quantum VQC\"\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"✅ Training complete!\")\n",
        "print(f\"Best Validation Accuracy: {max(history['val_acc']):.2f}%\")\n",
        "print(f\"{'='*70}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppUMTy7aTeoc",
        "outputId": "eb4a7b71-f2b8-4b15-e788-a1aef91e7268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TRAINING ADVANCED QUANTUM VQC MODEL\n",
            "  - 6 qubits with 64-amplitude encoding\n",
            "  - 3 layers with data re-uploading\n",
            "  - 15 quantum measurements (Z, ZZ, ZZZ)\n",
            "======================================================================\n",
            "\n",
            "Total parameters: 612\n",
            "Quantum parameters: 36\n",
            "Classical parameters: 576\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Advanced Quantum VQC] Epoch 1/20: 100%|██████████| 620/620 [29:15<00:00,  2.83s/it, loss=3.5592, acc=4.59%, lr=0.005000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Advanced Quantum VQC] Epoch 1/20:\n",
            "  Train Loss: 3.5672 | Train Acc: 4.59%\n",
            "  Val Loss: 3.5502 | Val Acc: 5.59%\n",
            "  LR: 0.005000\n",
            "  ✅ New best model saved! Val Acc: 5.59%\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Advanced Quantum VQC] Epoch 2/20: 100%|██████████| 620/620 [29:45<00:00,  2.88s/it, loss=3.5023, acc=6.85%, lr=0.004969]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Advanced Quantum VQC] Epoch 2/20:\n",
            "  Train Loss: 3.5281 | Train Acc: 6.85%\n",
            "  Val Loss: 3.5190 | Val Acc: 6.35%\n",
            "  LR: 0.004969\n",
            "  ✅ New best model saved! Val Acc: 6.35%\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Advanced Quantum VQC] Epoch 3/20: 100%|██████████| 620/620 [33:43<00:00,  3.26s/it, loss=3.4961, acc=7.71%, lr=0.004878]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Advanced Quantum VQC] Epoch 3/20:\n",
            "  Train Loss: 3.4983 | Train Acc: 7.71%\n",
            "  Val Loss: 3.4961 | Val Acc: 6.27%\n",
            "  LR: 0.004878\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Advanced Quantum VQC] Epoch 4/20: 100%|██████████| 620/620 [33:05<00:00,  3.20s/it, loss=3.4132, acc=8.03%, lr=0.004728]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Advanced Quantum VQC] Epoch 4/20:\n",
            "  Train Loss: 3.4753 | Train Acc: 8.03%\n",
            "  Val Loss: 3.4783 | Val Acc: 7.56%\n",
            "  LR: 0.004728\n",
            "  ✅ New best model saved! Val Acc: 7.56%\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Advanced Quantum VQC] Epoch 5/20: 100%|██████████| 620/620 [31:40<00:00,  3.07s/it, loss=3.4660, acc=8.74%, lr=0.004523]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Advanced Quantum VQC] Epoch 5/20:\n",
            "  Train Loss: 3.4564 | Train Acc: 8.74%\n",
            "  Val Loss: 3.4651 | Val Acc: 7.28%\n",
            "  LR: 0.004523\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Advanced Quantum VQC] Epoch 6/20: 100%|██████████| 620/620 [33:23<00:00,  3.23s/it, loss=3.4445, acc=8.48%, lr=0.004269]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Advanced Quantum VQC] Epoch 6/20:\n",
            "  Train Loss: 3.4415 | Train Acc: 8.48%\n",
            "  Val Loss: 3.4517 | Val Acc: 8.08%\n",
            "  LR: 0.004269\n",
            "  ✅ New best model saved! Val Acc: 8.08%\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Advanced Quantum VQC] Epoch 7/20: 100%|██████████| 620/620 [31:52<00:00,  3.08s/it, loss=3.4966, acc=8.85%, lr=0.003972]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Advanced Quantum VQC] Epoch 7/20:\n",
            "  Train Loss: 3.4293 | Train Acc: 8.85%\n",
            "  Val Loss: 3.4427 | Val Acc: 7.88%\n",
            "  LR: 0.003972\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Advanced Quantum VQC] Epoch 8/20:  93%|█████████▎| 575/620 [29:47<02:15,  3.00s/it, loss=3.4816, acc=9.35%, lr=0.003638]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== CELL 10 =====\n",
        "# Visualize results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "axes[0].plot(history['val_acc'], 'b-', linewidth=2.5, marker='o')\n",
        "axes[0].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Validation Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Validation Accuracy', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].axhline(y=max(history['val_acc']), color='r', linestyle='--',\n",
        "                label=f'Best: {max(history[\"val_acc\"]):.2f}%')\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(history['train_loss'], 'r-', linewidth=2.5, marker='s')\n",
        "axes[1].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Training Loss', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].plot(history['train_acc'], 'g-', linewidth=2.5, marker='^')\n",
        "axes[2].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "axes[2].set_ylabel('Training Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "axes[2].set_title('Training Accuracy', fontsize=14, fontweight='bold')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('advanced_quantum_results.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"FINAL RESULTS - ADVANCED QUANTUM VQC\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Best Validation Accuracy: {max(history['val_acc']):.2f}%\")\n",
        "print(f\"Final Training Accuracy: {history['train_acc'][-1]:.2f}%\")\n",
        "print(f\"Final Loss: {history['train_loss'][-1]:.4f}\")\n",
        "print(f\"{'='*70}\")"
      ],
      "metadata": {
        "id": "3MxoiBvSTgDl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}